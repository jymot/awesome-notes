# README


 * [è™šæ‹Ÿä¿¡ç”¨å¡ï¼Œå¼€é€šå›½å¤–æœåŠ¡](https://yeka.ai)

## å·¥å…·/æ¨¡å‹ç¤¾åŒº
 * [ollama](https://github.com/ollama/ollama)
   * Get up and running with Llama 3.3, DeepSeek-R1, Phi-4, Gemma 2, and other large language models.
   * å¼€å§‹ä½¿ç”¨Llama 3.3ã€DeepSeek-R1ã€Phi-4ã€Gemma 2å’Œå…¶ä»–å¤§å‹è¯­è¨€æ¨¡å‹ã€‚
 * [LM Studio](https://lmstudio.ai/)
   * å¤§æ¨¡å‹éƒ¨ç½²å·¥å…· 
   * [lms](https://github.com/lmstudio-ai/lms) LM Studio CLI
 * [lmdeploy](https://github.com/InternLM/lmdeploy)
   * LMDeploy is a toolkit for compressing, deploying, and serving LLMs. 
   * å¤§æ¨¡å‹éƒ¨ç½²å·¥å…· 
 * [sglang](https://github.com/sgl-project/sglang)
   * SGLang is a fast serving framework for large language models and vision language models.
   * å¤§æ¨¡å‹éƒ¨ç½²å·¥å…·
 * [vllm](https://github.com/vllm-project/vllm)
   * A high-throughput and memory-efficient inference and serving engine for LLMs
   * å¤§æ¨¡å‹éƒ¨ç½²å·¥å…·
 * [anything-llm](https://github.com/Mintplex-Labs/anything-llm)
   * The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, and more.
   * è¿™æ˜¯ä¸€ä¸ªå…¨æ ˆåº”ç”¨ç¨‹åºï¼Œå¯ä»¥å°†ä»»ä½•æ–‡æ¡£ã€èµ„æºï¼ˆå¦‚ç½‘å€é“¾æ¥ã€éŸ³é¢‘ã€è§†é¢‘ï¼‰æˆ–å†…å®¹ç‰‡æ®µè½¬æ¢ä¸ºä¸Šä¸‹æ–‡ï¼Œä»¥ä¾¿ä»»ä½•å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨èŠå¤©æœŸé—´ä½œä¸ºå‚è€ƒä½¿ç”¨ã€‚æ­¤åº”ç”¨ç¨‹åºå…è®¸æ‚¨é€‰æ‹©ä½¿ç”¨å“ªä¸ªLLMæˆ–å‘é‡æ•°æ®åº“ï¼ŒåŒæ—¶æ”¯æŒå¤šç”¨æˆ·ç®¡ç†å¹¶è®¾ç½®ä¸åŒæƒé™ã€‚
 * [cherry-studio](https://github.com/CherryHQ/cherry-studio)
   * ğŸ’ Cherry Studio is a desktop client that supports for multiple LLM providers. Support deepseek-r1
   * æ”¯æŒå¤šæœåŠ¡å•†çš„AIå¯¹è¯æ¡†å®¢æˆ·ç«¯
 * [ModelScope](https://www.modelscope.cn/home)
   * [modelscope github](https://github.com/modelscope) 
   * å¼€æºæ¨¡å‹ç¤¾åŒº
 * [huggingface](https://huggingface.co/spaces)
   * å¼€æºæ¨¡å‹ç¤¾åŒº
